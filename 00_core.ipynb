{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp core\n",
    "from nbdev import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series Feature Engineering Core\n",
    "\n",
    "> Basic functions for time series analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from typing import *\n",
    "from fastcore import *\n",
    "from fastcore.utils import *\n",
    "from fastcore.script import *\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def ifnone(a:Any,b:Any)->Any:\n",
    "    \"`a` if `a` is not None, otherwise `b`.\"\n",
    "    return b if a is None else a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def make_date(df, date_field):\n",
    "    \"Make sure `df[date_field]` is of the right date type.\"\n",
    "    field_dtype = df[date_field].dtype\n",
    "    if isinstance(field_dtype, pd.core.dtypes.dtypes.DatetimeTZDtype):\n",
    "        field_dtype = np.datetime64\n",
    "    if not np.issubdtype(field_dtype, np.datetime64):\n",
    "        df[date_field] = pd.to_datetime(df[date_field], infer_datetime_format=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def add_datepart(df, field_name, prefix=None, drop=True, time=False):\n",
    "    \"Helper function that adds columns relevant to a date in the column `field_name` of `df`.\"\n",
    "    make_date(df, field_name)\n",
    "    field = df[field_name]\n",
    "    prefix = ifnone(prefix, re.sub('[Dd]ate$', '', field_name))\n",
    "    attr = ['Year', 'Month', 'Week', 'Day', 'Dayofweek', 'Dayofyear', 'Is_month_end', 'Is_month_start',\n",
    "            'Is_quarter_end', 'Is_quarter_start', 'Is_year_end', 'Is_year_start']\n",
    "    if time: attr = attr + ['Hour', 'Minute', 'Second']\n",
    "    # Pandas removed `dt.week` in v1.1.10\n",
    "    week = field.dt.isocalendar().week.astype(field.dt.day.dtype) if hasattr(field.dt, 'isocalendar') else field.dt.week\n",
    "    for n in attr: df[prefix + n] = getattr(field.dt, n.lower()) if n != 'Week' else week\n",
    "    mask = ~field.isna()\n",
    "    df[prefix + 'Elapsed'] = np.where(mask,field.values.astype(np.int64) // 10 ** 9,None)\n",
    "    if drop: df.drop(field_name, axis=1, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def add_lag_features(df, field_name, prefix=None, lag_periods=[1]):\n",
    "    \"Helper function that adds lag features relevant to the column `field_name` of `df`.\"\n",
    "    field = df[field_name]\n",
    "    prefix = ifnone(prefix, field_name)\n",
    "    for n in lag_periods: df[f'{prefix}-{n}p'] = df[field_name].shift(n)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def add_lag_percentage_gain_features(df, field_name, prefix=None, lag_periods=[1]):\n",
    "    \"Helper function that adds lag percentage gain features relevant to the column `field_name` of `df`.\"\n",
    "    field = df[field_name]\n",
    "    prefix = ifnone(prefix, field_name)\n",
    "    for n in lag_periods:\n",
    "        df[f'{prefix}-{n}p_PG'] = df[field_name]/df[field_name].shift(n)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def add_moving_average_features(df, field_name, prefix=None, windows=[3], weighted=True):\n",
    "    \"Helper function that adds moving average (rolling window) features relevant to the column `field_name` of `df`.\"\n",
    "    field = df[field_name]\n",
    "    prefix = ifnone(prefix, field_name)\n",
    "    for n in windows:\n",
    "        if weighted:\n",
    "            weights = np.arange(1, n + 1)\n",
    "            df[f'{prefix}_{n}p_MA'] = df[field_name].rolling(\n",
    "                window=n).apply(lambda x: np.dot(x, weights) /\n",
    "                                       weights.sum(), raw=True)\n",
    "        else:\n",
    "            df[f'{prefix}_{n}p_MA'] = df[field_name].rolling(window=n).mean()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def add_moving_average_percentage_gain_features(df, field_name, prefix=None, windows=[3], weighted=True):\n",
    "    \"Helper function that adds moving average (rolling window) percentage gain features relevant to the column `field_name` of `df`.\"\n",
    "    field = df[field_name]\n",
    "    prefix = ifnone(prefix, field_name)\n",
    "    for n in windows:\n",
    "        if weighted:\n",
    "            weights = np.arange(1, n + 1)\n",
    "            df[f'{prefix}_{n}p_MA_PG'] = df[field_name]/df[field_name].rolling(\n",
    "                window=n).apply(lambda x: np.dot(x, weights) /\n",
    "                                       weights.sum(), raw=True)\n",
    "        else:\n",
    "            df[f'{prefix}_{n}p_MA_PG'] = df[field_name]/df[field_name].rolling(window=n).mean()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def add_expanding_features(df, field_name, prefix=None, period=7):\n",
    "    \"Helper function that adds expanding features relevant to the column `field_name` of `df`.\"\n",
    "    field = df[field_name]\n",
    "    prefix = ifnone(prefix, field_name)\n",
    "    df[f'{prefix}_{period}p_expanding'] = df[field_name].expanding(period).mean()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def add_trend_features(df, field_name, prefix=None, windows=[3]):\n",
    "    \"Helper function that adds trend features relevant to the column `field_name` of `df`.\"\n",
    "    field = df[field_name]\n",
    "    prefix = ifnone(prefix, field_name)\n",
    "    for n in windows:\n",
    "        df[f'{prefix}_{n}p_trend'] = (df[field_name]\n",
    "                .rolling(window=n)\n",
    "                .mean()\n",
    "                .diff()\n",
    "                .fillna(0))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script; notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
